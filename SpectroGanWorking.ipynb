{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ~~Make list~~\n",
    "2. ~~[Get GPU working?](https://pytorch.org/docs/stable/notes/faq.html)~~\n",
    "3. ~~Change model for generator Transposed convolution~~\n",
    "4. Compress using discriminator\n",
    "5. Debug training to find where memory goes WHOOOOOP\n",
    "\n",
    "\n",
    "4. Fix Checkerboard Pattern\n",
    "5. Train on single Genre\n",
    "6. Upgrade our Discriminator (More CNN)\n",
    "7. \"Tunning\" \n",
    "\n",
    "    a. Stride\n",
    "\n",
    "    b. ~~CNN Nonsense~~\n",
    "8. Run that shit all day\n",
    "9. Train to generate specific Genere\n",
    "10. Increase image resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "from fastbook import *\n",
    "#import torch\n",
    "#print(torch.cuda.is_available())\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import gc\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tired_bias = 0\n",
    "\n",
    "batch_number = 10\n",
    "\n",
    "epoch_number = 10\n",
    "\n",
    "z_dim = 10\n",
    "\n",
    "og_img_size =  [batch_number, z_dim , 8, 64]\n",
    "dimensions = (batch_number, 1, 128, 1024)\n",
    "noise_vec = [batch_number, z_dim]\n",
    "\n",
    "first_layer = 16\n",
    "second_layer = int(first_layer/2)\n",
    "third_layer = int(second_layer/2)\n",
    "fourth_layer = int(third_layer/2)\n",
    "\n",
    "POOPs = 30\n",
    "print_every = 1\n",
    "\n",
    "device = \"cuda\"\n",
    "#device = \"cpu\"\n",
    "\n",
    "#torch.manual_seed(2.4)\n",
    "#print(torch.cuda.initial_seed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.BASE_PATH = r\".\\all_temp\"\n",
    "#path = Path.BASE_PATH = r\".\\all\"\n",
    "\n",
    "music = DataBlock(blocks = (ImageBlock(cls=PILImageBW), CategoryBlock),\n",
    "        get_items= get_image_files,\n",
    "        splitter = RandomSplitter(seed = 23),\n",
    "        get_y = using_attr(RegexLabeller(r'^([^.]+)'), 'name'))\n",
    "dls = music.dataloaders(path, bs=batch_number)\n",
    "#dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music.summary(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            #nn.Conv2d(256, 512, 3),\n",
    "            #nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(15360, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            #nn.LeakyReLU()\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        return self.discriminator(image)\n",
    "\n",
    "#discriminator = Discriminator().cuda()\n",
    "#batch_x,y = dls.valid.one_batch()\n",
    "#x, y = batch_x.cuda(), y.cuda()\n",
    "#out = discriminator(batch_x)\n",
    "#out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    \"\"\"\n",
    "    Class for performing a reshape as a layer in a sequential model.\n",
    "    \"\"\"\n",
    "    def __init__(self, shape=[]):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.shape)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "            # (Optional)Set the extra information about this module. You can test\n",
    "            # it by printing an object of this class.\n",
    "            return 'shape={}'.format(\n",
    "                self.shape\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_gen_image(y):\n",
    "    y = y.clone()\n",
    "    image = y[0,0].detach().to(\"cpu\").numpy() \n",
    "    plt.figure(figsize=(40,10))\n",
    "    plt.imshow(image)\n",
    "    #im = Image.fromarray(image).convert('RGB')\n",
    "    #im.save(\"Generated.jpeg\")\n",
    "\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self, label):\n",
    "        super(PrintLayer, self).__init__()\n",
    "        self.counter = 0 \n",
    "        self.counter2 = 0\n",
    "        self.label = label\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        print(self.label)\n",
    "        print(x.shape)\n",
    "        view_gen_image(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image(gen):\n",
    "    x = torch.rand(noise_vec).to(\"cuda\")\n",
    "    y = gen(x)\n",
    "    image = torch.reshape(y, dimensions)\n",
    "    y = y.detach().to(\"cpu\").numpy()\n",
    "    y.ndim\n",
    "    image = image[0,0].detach().to(\"cpu\").numpy() \n",
    "    plt.figure(figsize=(40,10))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    #im = Image.fromarray(image).convert('RGB')\n",
    "    #im.save(\"Generated.jpeg\")\n",
    "    #return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old AreTwos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AreTwoGenThree(nn.Module):\n",
    "    #def __init__(self, z_dim=10, img_size=(64,16,213)):\n",
    "    def __init__(self, z_dim=10, img_size=(64,31,255)):\n",
    "        super(AreTwoGenThree, self).__init__()\n",
    "        self.flat_img = int(np.prod(img_size))\n",
    "        self.generator = nn.Sequential(\n",
    "            # Fully connected layers\n",
    "            nn.Linear(z_dim, 131072),\n",
    "            Reshape((1, 128, 1024)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(56560)\n",
    "class AreTwoGenTwo(nn.Module):\n",
    "    #def __init__(self, z_dim=10, img_size=(64,16,213)):\n",
    "    def __init__(self, z_dim=100, img_size=(64,31,255)):\n",
    "        super(AreTwoGenTwo, self).__init__()\n",
    "        self.flat_img = int(np.prod(img_size))\n",
    "        self.generator = nn.Sequential(\n",
    "            # Fully connected layers\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            #nn.ReLu(True),\n",
    "\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, self.flat_img),\n",
    "            #nn.ReLu(True),\n",
    "\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            Reshape(img_size),\n",
    "            PrintLayer(\"Post Linear\"),\n",
    "\n",
    "            nn.ConvTranspose2d(64,32, (2,2), stride=2, padding=0, bias=False),\n",
    "            PrintLayer(\"Conv2d 1\"),\n",
    "\n",
    "            nn.BatchNorm2d(32),\n",
    "            PrintLayer(\"Batch Norm 1\"),\n",
    "\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            PrintLayer(\"Relu1\"),\n",
    "\n",
    "            nn.ConvTranspose2d(32,1,(2,2), stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "            PrintLayer(\"ConvTranspose2\"),\n",
    "            \n",
    "            nn.Sigmoid(),\n",
    "            PrintLayer(\"Sigmoid\"),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "\n",
    "def test_gen():\n",
    "    x = torch.rand(4, 100).cuda()\n",
    "    gen = AreTwoGenTwo().cuda()\n",
    "    y = gen(x)\n",
    "    print(y.shape)\n",
    "    view_gen_image(y)\n",
    "#test_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AreTwoGenFour(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AreTwoGenFour, self).__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels = 10, out_channels = 10, kernel_size=(3,3), stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=10),\n",
    "            nn.ReLU(True),\n",
    "            #PrintLayer(\"1\"),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 10, out_channels = 10, kernel_size=(2,2), stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=10),\n",
    "            nn.ReLU(True),\n",
    "            #PrintLayer(\"2\"),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 10, out_channels = 1, kernel_size=(2,2), stride=2, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            #nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=1),\n",
    "            #nn.ReLU(True),\n",
    "            #PrintLayer(\"3\"),\n",
    "\n",
    "            #nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=(2,2), stride=2, padding=1),\n",
    "            #nn.BatchNorm2d(num_features=1),\n",
    "            #nn.ReLU(True),\n",
    "            #PrintLayer(\"4\"),\n",
    "\n",
    "            #nn.ConvTranspose2d(in_channels = 512, out_channels = 256, kernel_size=(2,2), stride=2, padding=1),\n",
    "            #nn.BatchNorm2d(num_features=256),\n",
    "            #nn.ReLU(True),\n",
    "            #PrintLayer(\"5\"),\n",
    "            \n",
    "            #nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size=(2,2), stride=2, padding=1),\n",
    "            #nn.BatchNorm2d(num_features=128),\n",
    "            #nn.ReLU(True),\n",
    "            #PrintLayer(\"6\"),\n",
    "            \n",
    "        )\n",
    "        self.output = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.generator(x)\n",
    "        return self.output(x)\n",
    "def test_gen():\n",
    "    x = torch.rand(4, 10, 32, 256).cuda()\n",
    "    #x = torch.rand(noise_vec).cuda()\n",
    "    gen = AreTwoGenFour().cuda()\n",
    "    y = gen(x)\n",
    "    #print(y.shape)\n",
    "    view_gen_image(y)\n",
    "    return y\n",
    "\n",
    "#y = test_gen()    \n",
    "#y = y.clone()\n",
    "#image = y[0,0].detach().to(\"cpu\").numpy() \n",
    "#print(image.shape)\n",
    "#plt.figure(figsize=(40,10))\n",
    "#plt.imshow(image)\n",
    "## 128 X 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current AreTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AreTwoGenFour2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AreTwoGenFour2, self).__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(noise_vec[1], np.prod(og_img_size[1:])),\n",
    "            nn.BatchNorm1d(np.prod(og_img_size[1:])),\n",
    "            Reshape(og_img_size[1:]),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = og_img_size[1], out_channels = first_layer, kernel_size=2, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=first_layer),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = first_layer, out_channels = second_layer, kernel_size=2, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=second_layer),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = second_layer, out_channels = third_layer, kernel_size=2, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=third_layer),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = third_layer, out_channels = 2, kernel_size=2, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            #nn.ConvTranspose2d(in_channels = 2, out_channels = 1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=1),\n",
    "            #nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(in_channels = 2,  out_channels = 1, kernel_size=1, stride=1, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            #nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size=(2,2), stride=2, padding=1, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=1),\n",
    "            #nn.ReLU(True),\n",
    "\n",
    "            #nn.ConvTranspose2d(in_channels = 512, out_channels = 256, kernel_size=(2,2), stride=2, padding=1, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=256),\n",
    "            #nn.ReLU(True),\n",
    "\n",
    "            #nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size=(2,2), stride=2, padding=1, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=128),\n",
    "            #nn.ReLU(True), \n",
    "        )\n",
    "        self.output = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.generator(x)\n",
    "        return self.output(x)\n",
    "\n",
    "def test_gen():\n",
    "    #x = torch.rand(4, 100, 32, 256).cuda()\n",
    "    x = torch.rand(noise_vec).cuda()\n",
    "    print(x.shape)\n",
    "    gen = AreTwoGenFour2().cuda()\n",
    "    y = gen(x)\n",
    "    print(y.shape)\n",
    "    view_gen_image(y)\n",
    "    return y\n",
    "\n",
    "y = test_gen()    \n",
    "y = y.clone()\n",
    "image = y[0,0].detach().to(\"cpu\").numpy() \n",
    "#print(image.shape)\n",
    "\n",
    "plt.figure(figsize=(40,10))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(num_images, z_dim, device=\"cuda\"):\n",
    "    noise = None\n",
    "    if device == \"cuda\":\n",
    "        noise = torch.rand(noise_vec , device=device).cuda()\n",
    "    else:\n",
    "        noise = torch.rand(noise_vec)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(gen, disc, criterion, real_input, num_images, z_dim, device=\"cuda\"):\n",
    "    '''\n",
    "    Return Loss of discriminator \n",
    "    Params: \n",
    "    Gen: Geneartor model\n",
    "    Disc: Discrimiator Model\n",
    "    criterion: Loss function\n",
    "    Real Input: Our data set images\n",
    "    Num_images: Len(real input)\n",
    "    z_dim: Dimention of our noise vector\n",
    "    Return a loss value for 1 batch\n",
    "    '''\n",
    "    \n",
    "    fake_images = gen(get_noise(num_images, z_dim, device=device))\n",
    "    fake_images = torch.reshape(fake_images, dimensions)\n",
    "    fake_images.detach()\n",
    "    fake_loss = criterion(disc(fake_images), torch.zeros((num_images,1),device=device))\n",
    "    real_loss = criterion(disc(real_input), torch.ones((num_images,1),device=device))\n",
    "    disc_loss = (fake_loss + real_loss)/2 + tired_bias\n",
    "    return disc_loss\n",
    "\n",
    "def test_disc():\n",
    "    gen = AreTwoGenTwo().cuda()\n",
    "    disc = Discriminator().cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    x,y = dls.valid.one_batch()\n",
    "    num_images = len(x)\n",
    "    z_dim = 10\n",
    "    loss = get_disc_loss(gen, disc, criterion, x, num_images, z_dim)\n",
    "    return loss\n",
    "    \n",
    "#loss = test_disc()\n",
    "#print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device=\"cuda\"):\n",
    "    '''\n",
    "    Returns the loss of the generator\n",
    "    Params: \n",
    "    Gen: Generator Model\n",
    "    Disc: Discrimiator Model\n",
    "    Criterion: Loss Function\n",
    "    num_images: The number of images the generator should produce\n",
    "    z_dim: The dim of the noise vector\n",
    "    Device: What device we run it on\n",
    "    '''\n",
    "    fake_images = gen(get_noise(num_images, z_dim, device=device))\n",
    "    fake_images = torch.reshape(fake_images, dimensions)\n",
    "    fake_images.detach()\n",
    "    prediction = disc(fake_images)\n",
    "    gen_loss = criterion(prediction, torch.ones(num_images,1, device=device))\n",
    "    return gen_loss\n",
    "\n",
    "def test_gen_loss():\n",
    "    gen = Generator().cuda()\n",
    "    disc = Discriminator().cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    num_images = 4 \n",
    "    z_dim = 10\n",
    "    loss = get_gen_loss(gen, disc, criterion, num_images, z_dim)\n",
    "    return loss\n",
    "\n",
    "#loss = test_gen_loss()\n",
    "#print(loss)\n",
    "#loss = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #criterion = nn.BCELoss\n",
    "# what we've been using\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "# whub whub converges at 40\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "# doesn't work\n",
    "\n",
    "#criterion = nn.L1Loss()\n",
    "# chirpy and musical really quiet without the whub whub converges at 20\n",
    "\n",
    "#criterion = nn.CTCLoss()\n",
    "# TypeError: forward() missing 2 required positional arguments: 'input_lengths' and 'target_lengths'\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "# RuntimeError: 0D or 1D target tensor expected, multi-target not supported\n",
    "\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "# so bad, basically nothing\n",
    "\n",
    "#criterion = nn.GaussianNLLLoss()\n",
    "# TypeError: forward() missing 1 required positional argument: 'var'\n",
    "\n",
    "#criterion = nn.KLDivLoss()\n",
    "# UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.\n",
    "# negative numbers lol\n",
    "# demonic shit\n",
    "\n",
    "#criterion = nn.MarginRankingLoss()\n",
    "# vTypeError: forward() missing 1 required positional argument: 'target'\n",
    "\n",
    "#criterion = nn.HingeEmbeddingLoss()\n",
    "# waste of time\n",
    "\n",
    "#criterion = nn.MultiLabelMarginLoss\n",
    "# RuntimeError: Boolean value of Tensor with more than one value is ambiguous\n",
    "\n",
    "#criterion = nn.HuberLoss()\n",
    "# literally nothing\n",
    "\n",
    "#criterion = nn.SmoothL1Loss()\n",
    "# literally nothing\n",
    "\n",
    "#criterion = nn.SoftMarginLoss()\n",
    "# converges on the first epoch\n",
    "\n",
    "#criterion = nn.MultiLabelSoftMarginLoss()\n",
    "# okay 90s kids tv show computer\n",
    "\n",
    "#criterion = nn.CosineEmbeddingLoss()\n",
    "# TypeError: forward() missing 1 required positional argument: 'target'\n",
    "\n",
    "#criterion = nn.MultiMarginLoss()\n",
    "# RuntimeError: inconsistent target size, expected 4 but got [4, 1]\n",
    "\n",
    "#criterion = nn.TripletMarginLoss()\n",
    "# TypeError: forward() missing 1 required positional argument: 'negative'\n",
    "\n",
    "# criterion = nn.TripletMarginWithDistanceLoss()\n",
    "# TypeError: forward() missing 1 required positional argument: 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# converges at 14 amazing whub but melodic A+\n",
    "\n",
    "#gen = AreTwoGenFour().to(device)\n",
    "#gen = AreTwoGenThree().to(device)\n",
    "gen = AreTwoGenFour2().to(device)\n",
    "\n",
    "\n",
    "gen_opt = torch.optim.Adam(gen.parameters())\n",
    "disc = Discriminator().to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters())\n",
    "\n",
    "cur_step = 0 \n",
    "disc_loss_hist = [] \n",
    "gen_loss_hist = []\n",
    "disc_loss_hist.append(25)\n",
    "gen_loss_hist.append(25)\n",
    "\n",
    "for epoch in range(epoch_number):\n",
    "    disc_loss_batch = 0.0\n",
    "    gen_loss_batch = 0.0\n",
    "    \n",
    "    for batch in dls.train:\n",
    "        real_images, *_ = batch\n",
    "        real_images = real_images.to(device)\n",
    "        num_images = len(real_images)\n",
    "\n",
    "        #Train discriminator\n",
    "        if gen_loss_hist[-1] < POOPs:\n",
    "            disc_opt.zero_grad()\n",
    "            disc_loss = get_disc_loss(gen, disc, criterion, real_images, num_images, z_dim, device)\n",
    "            disc_loss_batch+=disc_loss.item()\n",
    "            disc_loss.backward(retain_graph=True)\n",
    "            disc_opt.step()\n",
    "\n",
    "        #Train Generator\n",
    "        gen_opt.zero_grad()\n",
    "        gen_loss = get_gen_loss(gen, disc, criterion, num_images, z_dim, device)\n",
    "        gen_loss_batch+=gen_loss.item()\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        gen_opt.step()\n",
    "\n",
    "    print(\"Epoch: \" + str(epoch + 1))\n",
    "    print(disc_loss_batch/batch_number)\n",
    "    print(gen_loss_batch/batch_number)\n",
    "\n",
    "    disc_loss_hist.append(disc_loss_batch/batch_number)\n",
    "    gen_loss_hist.append(gen_loss_batch/batch_number)\n",
    "\n",
    "    if epoch % (print_every) == 0: \n",
    "        make_image(gen)\n",
    "        for i in range(1):\n",
    "            fake_images = gen(get_noise(num_images, z_dim, device=device))\n",
    "            fake_images = torch.reshape(fake_images, dimensions)\n",
    "            fake_images.detach()\n",
    "            prediction = disc(fake_images)\n",
    "            print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(disc_loss_hist)\n",
    "\n",
    "ax.set_xlim(0,40)\n",
    "ax.set_ylim(0, 60)\n",
    "\n",
    "ax.plot(gen_loss_hist)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image(gen):\n",
    "    x = torch.rand(noise_vec).to(\"cuda\")\n",
    "    y = gen(x)\n",
    "\n",
    "    image = torch.reshape(y, dimensions)\n",
    "\n",
    "    y = y.detach().to(\"cpu\").numpy()\n",
    "    y.ndim\n",
    "\n",
    "    image = image[0,0].detach().to(\"cpu\").numpy()\n",
    "\n",
    "    plt.figure(figsize=(40,10))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    im = Image.fromarray(image).convert('RGB')\n",
    "    im.save(\"Generated.jpeg\")\n",
    "\n",
    "    return image\n",
    "\n",
    "def create_wav_file(image, file_name):\n",
    "    S = librosa.feature.inverse.mel_to_stft(image, norm='slaney')\n",
    "    y = librosa.griffinlim(S)\n",
    "    \n",
    "    sf.write(file_name, y, 22050)\n",
    "\n",
    "image = make_image(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_wav_file(image, \"test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(r\"C:\\Users\\ldscho\\spectro\\ml_expore\\test.wav\", duration=23)\n",
    "S = np.abs(librosa.stft(y))\n",
    "\n",
    "S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "plt.figure()\n",
    "librosa.display.specshow(S_db)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrogram(x, sr, save_name):\n",
    "    #Creates the spectro gram\n",
    "    spectro = librosa.sft(x)\n",
    "    #Convert to decible \n",
    "    #Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(66,854))\n",
    "    ax = fig.add_axes([0,0,1,1], frameon=False)\n",
    "    ax.axis(\"off\")\n",
    "    librosa.display.specshow(spectro, sr=sr, cmap='grey', x_axis='time', y_axis =\"hz\")\n",
    "    plt.savefig(save_name, quality=100, bbox_inches=0, pad_inches=0)\n",
    "    librosa.cache.clear()\n",
    "    return spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write(\"example2.wav\", samplerate, lInverse.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(r\"C:\\Users\\ldscho\\Downloads\\pop.00001.wav\")\n",
    "M = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "lM = M.astype(np.uint8)\n",
    "\n",
    "im = Image.fromarray(lM)\n",
    "im.save(\"lM.png\")\n",
    "\n",
    "#image = Image.open(r\"C:\\Users\\ldscho\\spectro\\ml_expore\\lM.png\")\n",
    "#data = np.asarray(image)\n",
    "\n",
    "S = librosa.feature.inverse.mel_to_stft(data.astype(np.float64))\n",
    "y = librosa.griffinlim(S)\n",
    "\n",
    "sf.write(\"lM.wav\", y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "librosa.display.specshow(M)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectrogram_and_back():\n",
    "    x, sr = librosa.load(r\"C:\\Users\\ldscho\\Downloads\\blues.00007.wav\", duration=10)\n",
    "    S = np.abs(librosa.stft(x))\n",
    "    x_inv = librosa.griffinlim(S)\n",
    "    sf.write(\"examplefinal.wav\", x_inv, sr)\n",
    "    return x_inv, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = audio_to_spectrogram_and_back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_generate(path):\n",
    "    #[^\\]*(?=[.][a-zA-Z]+$)\n",
    "    pattern = re.compile(r'(.+)(\\\\)(?P<name>.+)(.wav)')\n",
    "    for music_name in os.listdir(path):\n",
    "        file_name = os.path.join(path, music_name)\n",
    "        if os.path.isfile(file_name):\n",
    "            match = list((re.finditer(pattern, file_name)))\n",
    "            name = match[0].groupdict()['name']\n",
    "            print(file_name)\n",
    "\n",
    "            y, sr = librosa.load(file_name, duration=23.77)\n",
    "            M = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "            lM = M.astype(np.uint8)\n",
    "\n",
    "            im = Image.fromarray(lM)\n",
    "            im.save(name + \".png\")\n",
    "\n",
    "#mel_generate(r\"C:\\Users\\ldscho\\spectro\\ml_expore\\all\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "331064a27407ea7c8d6f0bbf427f600a0074c92925d58e18630a46bdc7f6e71b"
  },
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit ('real-fast': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
