{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ~~Make list~~\n",
    "2. ~~[Get GPU working?](https://pytorch.org/docs/stable/notes/faq.html)~~\n",
    "3. ~~Change model for generator Transposed convolution~~\n",
    "4. Compress using discriminator\n",
    "5. Debug training to find where memory goes WHOOOOOP\n",
    "\n",
    "\n",
    "4. Fix Checkerboard Pattern\n",
    "5. Train on single Genre\n",
    "6. Upgrade our Discriminator (More CNN)\n",
    "7. \"Tunning\" \n",
    "\n",
    "    a. Stride\n",
    "\n",
    "    b. ~~CNN Nonsense~~\n",
    "8. Run that shit all day\n",
    "9. Train to generate specific Genere\n",
    "10. Increase image resolution \n",
    "\n",
    "\n",
    "Resolution Improvement\n",
    "1. Skip connections\n",
    "2. Learning rate\n",
    "3. New Datase\n",
    "4. More Conv Layers between upsacles\n",
    "4. Slow down upscaling\n",
    "5. Go bigger then scale down\n",
    "6. Max pool?  \n",
    "5. ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "from fastbook import *\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "model_selection = \"ProGan\"\n",
    "#model_selection = \"SmoothGan\"\n",
    "\n",
    "batch_number = 10 # 4\n",
    "\n",
    "epoch_number = 250\n",
    "\n",
    "label_smoothing = False\n",
    "\n",
    "disc_lr=0.0001\n",
    "gen_lr=0.0001\n",
    "\n",
    "z_dim = 10\n",
    "\n",
    "og_img_size =  [batch_number, z_dim , 4, 4] #32\n",
    "dimensions = (batch_number, 1, 512, 512)\n",
    "noise_vec = [batch_number, z_dim]\n",
    "\n",
    "init_alpha =.5\n",
    "inc_alpha = .1\n",
    "\n",
    "print_every = 1\n",
    "\n",
    "print_layers = False\n",
    "\n",
    "\n",
    "progan_seq = [4, 8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "prodisc_seq = progan_seq[::-1]\n",
    "max_num_blocks = len(progan_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = Path.BASE_PATH = r\"./squash_mel\"\n",
    "path = Path.BASE_PATH = r\"./train_half\"\n",
    "\n",
    "music = DataBlock(blocks = (ImageBlock(cls=PILImageBW)),\n",
    "        get_items= get_image_files,\n",
    "        splitter = RandomSplitter(seed = 23))\n",
    "\n",
    "dls = music.dataloaders(path, bs=batch_number)\n",
    "\n",
    "music.summary(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_conv, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels =16, kernel_size=3, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels =16, out_channels =32,  kernel_size=3, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels =32, out_channels =64,  kernel_size=3, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels =64, out_channels =32,  kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels =32, out_channels =1,  kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        b = self.discriminator(image).view(batch_number, -1)\n",
    "        return b\n",
    "\n",
    "#discriminator = Discriminator_conv().cuda()\n",
    "#batch_x = dls.valid.one_batch()[0]\n",
    "#x = batch_x.cuda()\n",
    "#out = discriminator(batch_x)\n",
    "#print(out)\n",
    "#out = out.view(batch_number, -1)\n",
    "#out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    \"\"\"\n",
    "    Class for performing a reshape as a layer in a sequential model.\n",
    "    \"\"\"\n",
    "    def __init__(self, shape=[]):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.shape)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "            # (Optional)Set the extra information about this module. You can test\n",
    "            # it by printing an object of this class.\n",
    "            return 'shape={}'.format(\n",
    "                self.shape\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_gen_image(y):\n",
    "    y = y.clone()\n",
    "    image = y[0,0].detach().to(\"cpu\").numpy() \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "    \n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self, label):\n",
    "        super(PrintLayer, self).__init__()\n",
    "        self.label = label\n",
    "\n",
    "    def forward(self, x):\n",
    "        if print_layers:\n",
    "            print(self.label)\n",
    "            print(x.shape)\n",
    "            view_gen_image(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image(gen):\n",
    "    x = torch.rand(noise_vec).to(\"cuda\")\n",
    "    y = gen(x)\n",
    "    \n",
    "    image = torch.reshape(y, dimensions)\n",
    "    \n",
    "    y = y.detach().to(\"cpu\").numpy()\n",
    "    y.ndim\n",
    "    \n",
    "    image = image[0,0].detach().to(\"cpu\").numpy() \n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current AreTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class AreTwoGenFourSmoothSquare(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(noise_vec[1], np.prod(og_img_size[1:])),\n",
    "            nn.BatchNorm1d(np.prod(og_img_size[1:])),\n",
    "            nn.ReLU(True),\n",
    "        \n",
    "            nn.Linear(np.prod(og_img_size[1:]), np.prod(og_img_size[1:])),\n",
    "            nn.BatchNorm1d(np.prod(og_img_size[1:])),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            Reshape(og_img_size[1:]),\n",
    "            \n",
    "            PrintLayer(\"Pre Conv2\"),\n",
    "\n",
    "            nn.Conv2d(in_channels = og_img_size[1],  out_channels = 1024, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=1024, momentum = 0.7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            PrintLayer(\"Chunk1\"),\n",
    "\n",
    "            nn.Conv2d(in_channels = 1024,  out_channels = 512, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=512, momentum = 0.7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            PrintLayer(\"Chunk2\"),\n",
    "\n",
    "            nn.Conv2d(in_channels = 512,  out_channels = 256, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256, momentum = 0.7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            PrintLayer(\"Chunk3\"),\n",
    "\n",
    "            nn.Conv2d(in_channels = 256,  out_channels = 128, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=128, momentum = 0.7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            PrintLayer(\"Chunk4\"),\n",
    "\n",
    "            nn.Conv2d(in_channels = 128,  out_channels = 64, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=64, momentum = 0.7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            \n",
    "            PrintLayer(\"Chunk5\"),\n",
    "            \n",
    "            nn.Conv2d(in_channels = 64,  out_channels = 32 , kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=32, momentum = 0.7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            PrintLayer(\"Chunk6\"),\n",
    "            \n",
    "            nn.Conv2d(in_channels = 32,  out_channels = 16 , kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=16, momentum = 0.7),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            PrintLayer(\"Chunk6\"),\n",
    "            \n",
    "            nn.Conv2d(in_channels = 16,  out_channels = 1, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "\n",
    "            PrintLayer(\"Chunk6\"),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.generator(x)\n",
    "        return x\n",
    "\n",
    "def test_gen():\n",
    "    x = torch.rand(noise_vec).cuda()\n",
    "    print(x.shape)\n",
    "    gen = AreTwoGenFourSmoothSquare().cuda()\n",
    "    y = gen(x)\n",
    "    print(y.shape)\n",
    "    view_gen_image(y)\n",
    "    return y\n",
    "\n",
    "#y = test_gen()    \n",
    "#y = y.clone()\n",
    "#image = y[0,0].detach().to(\"cpu\").numpy() \n",
    "#print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProConGan(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.ModuleList([ProGanBlock(z_dim, 512)])\n",
    "        self.alpha = init_alpha\n",
    "        self.alpha_increment = inc_alpha\n",
    "        self.toBW =  nn.ModuleList([nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, bias=False).cuda()])\n",
    "        self.dim_progression = progan_seq\n",
    "        self.model_size = len(self.dim_progression)-1\n",
    "        self.dim_index = 0\n",
    "\n",
    "    def add_block(self):\n",
    "        self.model.append(nn.Upsample(scale_factor=2))\n",
    "        in_shape = self.dim_progression[self.model_size-(self.dim_index)]\n",
    "        out_shape =self.dim_progression[max(0,self.model_size-(self.dim_index+1))]\n",
    "        \n",
    "        self.model.append(ProGanBlock(in_channels=in_shape, \\\n",
    "            out_channels=out_shape).cuda())\n",
    "\n",
    "        if len(self.model) == 3:\n",
    "            self.toBW.append(nn.Conv2d(in_channels=out_shape, out_channels=1, kernel_size=1, stride=1, bias=False).cuda())\n",
    "        else:\n",
    "            self.toBW[0] = self.toBW[1]\n",
    "            self.toBW[1] = nn.Conv2d(in_channels=out_shape, out_channels=1, kernel_size=1, stride=1, bias=False).cuda()\n",
    "        \n",
    "\n",
    "        self.reset_alpha()\n",
    "        self.dim_index += 1\n",
    "        #Replace to BW\n",
    "\n",
    "    def increment_alpha(self):\n",
    "        self.alpha = self.alpha+self.alpha_increment\n",
    "        self.alpha = min(1, self.alpha)\n",
    "    \n",
    "    def reset_alpha(self):\n",
    "        self.alpha = init_alpha\n",
    "\n",
    "    def get_dim(self):\n",
    "        return self.dim_progression[self.dim_index]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.model):\n",
    "            if i<len(self.model)-1 or len(self.model) == 1:\n",
    "                x = layer(x)\n",
    "                if len(self.model) == 1:\n",
    "                    #print(x.shape)\n",
    "                    x = self.toBW[0](x)\n",
    "            else:\n",
    "                x = self.toBW[1](self.alpha*layer(x)) + self.toBW[0]((1-self.alpha)*(x))\n",
    "        return x\n",
    "\n",
    "class ProGanBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "def test_progan():\n",
    "    pro = ProConGan().cuda()\n",
    "    x = torch.rand([10,1,4,4]).cuda()\n",
    "    for i in range(8):\n",
    "        y = pro(x)\n",
    "        print(y.shape)\n",
    "        pro.add_block()\n",
    "        pro.increment_alpha()\n",
    "    view_gen_image(y)\n",
    "    print(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProConDisc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.model = nn.ModuleList([ProDiscBlock(1, 4), nn.Flatten(), nn.Linear(int(np.prod(og_img_size)/batch_number), 1)])\n",
    "        self.model = nn.ModuleList([ProDiscBlock(2, 5), \n",
    "                                    FinalDiscBlock(2, 1),\n",
    "                                    FinalDiscBlock(1, 1)\n",
    "                                   ])\n",
    "        self.alpha = init_alpha\n",
    "        self.alpha_increment = inc_alpha\n",
    "        self.fromBW =  nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=4, kernel_size=1, stride=1).cuda()])\n",
    "        self.dim_progression = prodisc_seq\n",
    "        self.dim_index=0\n",
    "        self.model_size = len(self.dim_progression)-1 \n",
    "\n",
    "    def add_block(self):\n",
    "        in_shape = self.dim_progression[self.model_size-(self.dim_index)]\n",
    "        out_shape =self.dim_progression[max(0,self.model_size-(self.dim_index+1))]\n",
    "\n",
    "        if len(self.model) == 3:\n",
    "            self.fromBW.append(nn.Conv2d(in_channels=1, out_channels=out_shape, kernel_size=1, stride=1).cuda())\n",
    "        else:\n",
    "            self.fromBW[0] = self.fromBW[1]\n",
    "            self.fromBW[1] = nn.Conv2d(in_channels=1, out_channels=out_shape, kernel_size=1, stride=1).cuda()\n",
    "\n",
    "        self.model.insert(0,nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        self.model.insert(0,ProDiscBlock(in_shape, out_shape).cuda())\n",
    "        self.reset_alpha()\n",
    "        self.dim_index+=1\n",
    "\n",
    "        \n",
    "\n",
    "    def minibatch_std(self, x):\n",
    "        batch_statistics = (\n",
    "            torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "        )\n",
    "        # we take the std for each example (across all channels, and pixels) then we repeat it\n",
    "        # for a single channel and concatenate it with the image. In this way the discriminator\n",
    "        # will get information about the variation in the batch/image\n",
    "        return torch.cat([x, batch_statistics], dim=1)\n",
    "        \n",
    "    def increment_alpha(self):\n",
    "        self.alpha = self.alpha+self.alpha_increment\n",
    "        self.alpha = min(1, self.alpha)\n",
    "    \n",
    "    def reset_alpha(self):\n",
    "        self.alpha = init_alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        #model[0] is the CNN layer\n",
    "        #model[1] is the avg pool layer\n",
    "        if len(self.model) > 3:\n",
    "    \n",
    "            x_1 = self.fromBW[1](x)\n",
    "            x_1 = self.model[0](x_1)\n",
    "            x_1 = self.model[1](x_1)\n",
    "\n",
    "            x_2 = self.model[1](x)\n",
    "            x_2 = self.fromBW[0](x_2)\n",
    "            x = self.alpha * x_1 + (1-self.alpha)*x_2\n",
    "            \n",
    "        for i, layer in enumerate(self.model):\n",
    "            if len(self.model) == 3 and i ==0:\n",
    "                x = self.fromBW[0](x)\n",
    "                x = self.minibatch_std(x)\n",
    "            if i>1 or len(self.model) == 3: \n",
    "                if i+3 == len(self.model) and len(self.model) !=3:\n",
    "                    x = self.minibatch_std(x)\n",
    "                x = layer(x) \n",
    "        return x[:,:,0,0]\n",
    "    \n",
    "    \n",
    "class ProDiscBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            PixelNorm(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            PixelNorm(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "        \n",
    "class FinalDiscBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
    "    \n",
    "\n",
    "\n",
    "def test_discgan():\n",
    "    pro = ProConGan().cuda()\n",
    "    disc = ProConDisc().cuda()\n",
    "    x = torch.rand([10,1,4,4]).cuda()\n",
    "    batch_x = dls.valid.one_batch()[0]\n",
    "    batch_x =downsample(7, batch_x)\n",
    "    #print(disc(batch_x))\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(\"EPOCH\")\n",
    "        y = pro(x)\n",
    "        result = disc(y)\n",
    "        pro.add_block()\n",
    "        disc.add_block()\n",
    "        pro.increment_alpha()\n",
    "    \n",
    "#test_discgan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownDownDown(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.AvgPool2d(2,2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_label_smoothing(labels):\n",
    "    if label_smoothing:\n",
    "        return labels - torch.rand(labels.shape)*.1\n",
    "    else:\n",
    "        return labels\n",
    "    \n",
    "def negative_label_smoothing(labels):\n",
    "    if label_smoothing:\n",
    "        return labels + torch.rand(labels.shape)*.1\n",
    "    else:\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(n_times, image):\n",
    "    pool =  DownDownDown()\n",
    "    for n in range(n_times):\n",
    "        image = pool(image)\n",
    "    return image\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(num_images, z_dim, device=\"cuda\"):\n",
    "    noise = None\n",
    "    if device == \"cuda\":\n",
    "        if model_selection != \"ProGan\":\n",
    "            noise = torch.rand(noise_vec , device=device).cuda()\n",
    "        else:\n",
    "            noise = torch.rand(og_img_size , device=device).cuda()\n",
    "    else:\n",
    "        noise = torch.rand(noise_vec)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(gen, disc, criterion, real_input, num_images, z_dim, device=\"cuda\"):\n",
    "    '''\n",
    "    Return Loss of discriminator \n",
    "    Params: \n",
    "    Gen: Geneartor model\n",
    "    Disc: Discrimiator Model\n",
    "    criterion: Loss function\n",
    "    Real Input: Our data set images\n",
    "    Num_images: Len(real input)\n",
    "    z_dim: Dimention of our noise vector\n",
    "    Return a loss value for 1 batch\n",
    "    '''\n",
    "\n",
    "    real_input = downsample((7-disc.dim_index), real_input)\n",
    "    \n",
    "    fake_images = gen(get_noise(num_images, z_dim, device=device))\n",
    "    if model_selection == \"ProGan\":\n",
    "        fake_images = torch.reshape(fake_images, (batch_number, 1, gen.get_dim(), gen.get_dim()))\n",
    "    else: \n",
    "        fake_images = torch.reshape(fake_images, dimensions)\n",
    "    fake_images.detach()\n",
    "    \n",
    "    fake_labels = negative_label_smoothing(torch.zeros((num_images,1),device=device))\n",
    "    real_labels = positive_label_smoothing(torch.ones((num_images,1),device=device))                                    \n",
    "\n",
    "    fake_loss = criterion(disc(fake_images), fake_labels)\n",
    "    real_loss = criterion(disc(real_input), real_labels)\n",
    "    disc_loss = (fake_loss + real_loss)/2\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss_wgan(gen, disc, real_images, device=\"cuda\"):\n",
    "    fake_images = gen(get_noise(num_images, z_dim, device=device))\n",
    "    fake_images = torch.reshape(fake_images, dimensions)\n",
    "    fake_images.detach()\n",
    "\n",
    "    fake_pred = disc(fake_images)\n",
    "    real_pred = disc(real_images)\n",
    "    disc_loss = -(torch.mean(real_pred) - torch.mean(fake_pred))\n",
    "    return disc_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device=\"cuda\"):\n",
    "    '''\n",
    "    Returns the loss of the generator\n",
    "    Params: \n",
    "    Gen: Generator Model\n",
    "    Disc: Discrimiator Model\n",
    "    Criterion: Loss Function\n",
    "    num_images: The number of images the generator should produce\n",
    "    z_dim: The dim of the noise vector\n",
    "    Device: What device we run it on\n",
    "    '''\n",
    "    fake_images = gen(get_noise(num_images, z_dim, device=device))\n",
    "    if model_selection == \"ProGan\":\n",
    "        fake_images = torch.reshape(fake_images, (batch_number, 1, gen.get_dim(), gen.get_dim()))\n",
    "    else: \n",
    "        fake_images = torch.reshape(fake_images, dimensions)\n",
    "    fake_images.detach()\n",
    "    \n",
    "    real_labels = positive_label_smoothing(torch.ones((num_images,1),device=device)) \n",
    "    \n",
    "    prediction = disc(fake_images)\n",
    "    gen_loss = criterion(prediction, real_labels)\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss_wgan(gen, disc, real_images, device=\"cuda\"):\n",
    "    fake_images = gen(get_noise(num_images, z_dim, device=device))\n",
    "    fake_images = torch.reshape(fake_images, dimensions)\n",
    "    fake_images.detach()\n",
    "\n",
    "    fake_pred = disc(fake_images)\n",
    "    gen_loss = -torch.mean(fake_pred)\n",
    "\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.BCELoss\n",
    "# what we've been using\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "# whub whub converges at 40\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "# doesn't work\n",
    "\n",
    "#criterion = nn.L1Loss()\n",
    "# chirpy and musical really quiet without the whub whub converges at 20\n",
    "\n",
    "#criterion = nn.CTCLoss()\n",
    "# TypeError: forward() missing 2 required positional arguments: 'input_lengths' and 'target_lengths'\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "# RuntimeError: 0D or 1D target tensor expected, multi-target not supported\n",
    "\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "# so bad, basically nothing\n",
    "\n",
    "#criterion = nn.GaussianNLLLoss()\n",
    "# TypeError: forward() missing 1 required positional argument: 'var'\n",
    "\n",
    "#criterion = nn.KLDivLoss()\n",
    "# UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.\n",
    "# negative numbers lol\n",
    "# demonic shit\n",
    "\n",
    "#criterion = nn.MarginRankingLoss()\n",
    "# vTypeError: forward() missing 1 required positional argument: 'target'\n",
    "\n",
    "#criterion = nn.HingeEmbeddingLoss()\n",
    "# waste of time\n",
    "\n",
    "#criterion = nn.MultiLabelMarginLoss\n",
    "# RuntimeError: Boolean value of Tensor with more than one value is ambiguous\n",
    "\n",
    "#criterion = nn.HuberLoss()\n",
    "# literally nothing\n",
    "\n",
    "#criterion = nn.SmoothL1Loss()\n",
    "# literally nothing\n",
    "\n",
    "#criterion = nn.SoftMarginLoss()\n",
    "# converges on the first epoch\n",
    "\n",
    "#criterion = nn.MultiLabelSoftMarginLoss()\n",
    "# okay 90s kids tv show computer\n",
    "\n",
    "#criterion = nn.CosineEmbeddingLoss()\n",
    "# TypeError: forward() missing 1 required positional argument: 'target'\n",
    "\n",
    "#criterion = nn.MultiMarginLoss()\n",
    "# RuntimeError: inconsistent target size, expected 4 but got [4, 1]\n",
    "\n",
    "#criterion = nn.TripletMarginLoss()\n",
    "# TypeError: forward() missing 1 required positional argument: 'negative'\n",
    "\n",
    "# criterion = nn.TripletMarginWithDistanceLoss()\n",
    "# TypeError: forward() missing 1 required positional argument: 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%y%d%H%M%S\")\n",
    "\n",
    "out_path = os.path.join(\"./\", current_time)\n",
    "os.mkdir(out_path)\n",
    "\n",
    "def make_image4(gen, name):\n",
    "    x = get_noise(num_images, z_dim, device=device).to(\"cuda\")\n",
    "    y = gen(x)\n",
    "    y = y[0,0].detach().to(\"cpu\").numpy()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(y, cmap = \"gray\")\n",
    "    plt.savefig(out_path+\"/Generated\"+str(name)+\".png\")\n",
    "    plt.show()\n",
    "    np.save(out_path+\"/Generated\"+str(name), y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_metric(disc, gen):\n",
    "    reals = []\n",
    "    fakes = []\n",
    "    for i in range(25):\n",
    "        reals.append(np.mean(disc(dls.valid.one_batch())))\n",
    "        fakes.append(np.mean(disc(gen(get_noise(num_images, z_dim, device=device)))))\n",
    "    return np.mean(reals), np.mean(fakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert(True) #lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_layers = False\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# converges at 14 amazing whub but melodic A+\n",
    "\n",
    "gan = None\n",
    "disc = None\n",
    "\n",
    "block_count = 0\n",
    "\n",
    "if model_selection == \"ProGan\":\n",
    "    gen = ProConGan().to(device)\n",
    "    disc = ProConDisc().to(device)\n",
    "elif model_selection == \"SmoothGan\":\n",
    "    gen = AreTwoGenFourSmoothSquare().to(device)\n",
    "    disc = Discriminator_conv().to(device)\n",
    "\n",
    "#NON WGAN\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=gen_lr)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=disc_lr)\n",
    "\n",
    "#WGAN\n",
    "#gen_opt = torch.optim.RMSprop(gen.parameters())\n",
    "#disc_opt = torch.optim.RMSprop(disc.parameters())\n",
    "\n",
    "\n",
    "disc_loss_hist = [] \n",
    "gen_loss_hist = []\n",
    "\n",
    "disc_metric_real = []\n",
    "disc_metric_fake = []\n",
    "\n",
    "\n",
    "for epoch in range(epoch_number):\n",
    "    disc_loss_batch = 0.0\n",
    "    gen_loss_batch = 0.0\n",
    "    for batch in dls.train:\n",
    "        real_images, *_ = batch\n",
    "        real_images = real_images.to(device)\n",
    "        num_images = len(real_images)\n",
    "\n",
    "        #Train Generator\n",
    "        gen_opt.zero_grad()\n",
    "        \n",
    "        gen_loss = get_gen_loss(gen, disc, criterion, num_images, z_dim, device)\n",
    "        #gen_loss = get_gen_loss_wgan(gen, disc, real_images)\n",
    "        \n",
    "        gen_loss_batch+=gen_loss.item()\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        gen_opt.step()\n",
    "\n",
    "        ##Train discriminator\n",
    "        disc_opt.zero_grad()\n",
    "        \n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real_images, num_images, z_dim, device)\n",
    "        #disc_loss = get_disc_loss_wgan(gen, disc, real_images)\n",
    "        \n",
    "        disc_loss_batch+=disc_loss.item()\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step()\n",
    "        \n",
    "        if model_selection == \"ProGan\":\n",
    "            gen.increment_alpha()\n",
    "            disc.increment_alpha()\n",
    "\n",
    "\n",
    "    print(\"Finished epoch\")\n",
    "    print(\"Alpha: \"+ str(gen.alpha))\n",
    "    if epoch % 10==0 and epoch !=0 and gen.dim_index !=8 and block_count < max_num_blocks:\n",
    "        gen.add_block()\n",
    "        disc.add_block()\n",
    "        print(\"adding block\")\n",
    "        block_count += 1\n",
    "\n",
    "\n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    print(disc_loss_batch/batch_number)\n",
    "    print((gen_loss_batch/batch_number)) #WHY?\n",
    "\n",
    "    disc_loss_hist.append(disc_loss_batch/batch_number)\n",
    "    gen_loss_hist.append(gen_loss_batch/batch_number)\n",
    "\n",
    "    if epoch % (print_every) == 0: \n",
    "        for i in range(1):\n",
    "            make_image4(gen,epoch)\n",
    "            reals = downsample((7-disc.dim_index), real_images)\n",
    "            reals = reals.detach().to(\"cpu\").numpy()[0][0]\n",
    "            print(reals.shape)\n",
    "            fake_images = gen(get_noise(num_images, z_dim, device=device))\n",
    "            #fake_images = torch.reshape(fake_images, dimensions)\n",
    "            #fake_images.detach()\n",
    "            print(\"REAL\")\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(reals, cmap = \"gray\")\n",
    "            plt.show()\n",
    "            \n",
    "            fake_images = torch.reshape(fake_images, (batch_number, 1, gen.get_dim(), gen.get_dim()))\n",
    "            fake_images.detach()\n",
    "            prediction = disc(fake_images)\n",
    "            print(prediction)\n",
    "   #if epoch % 10: \n",
    "   #    real, fake = disc_metric(disc, gen)\n",
    "   #    disc_metric_real.append(real)\n",
    "   #    disc_metric_fake.append(fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(disc_loss_hist)\n",
    "\n",
    "ax.set_xlim(0,200)\n",
    "ax.set_ylim(1.9, 2.1)\n",
    "\n",
    "ax.plot(np.array(gen_loss_hist))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_layers = True\n",
    "x = torch.rand(noise_vec).to(\"cuda\")\n",
    "y = gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_numpy(filename):\n",
    "    gen_out = np.load(filename)\n",
    "    image = gen_out[0,0]\n",
    "    \n",
    "    return image\n",
    "\n",
    "def make_image3(gen):\n",
    "    x = torch.rand(noise_vec).to(\"cuda\")\n",
    "    y = gen(x)\n",
    "\n",
    "    image = torch.reshape(y, dimensions)\n",
    "\n",
    "\n",
    "    image = image[0,0].detach().to(\"cpu\").numpy()\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "\n",
    "    im = Image.fromarray(image).convert('RGB')\n",
    "    im.save(\"Generated.jpeg\")\n",
    "\n",
    "    return image\n",
    "\n",
    "def create_wav_file(image, file_name):\n",
    "    S = librosa.feature.inverse.mel_to_stft(image, norm='slaney')\n",
    "    y = librosa.griffinlim(S)\n",
    "    \n",
    "    sf.write(file_name, y, 22050)\n",
    "\n",
    "##image = make_image3(gen)\n",
    "print_layers = [286, 274, 242, 190, 183, 156, 137, 128, 111, 101, 91, 62, 27]\n",
    "\n",
    "for layer in print_layers:\n",
    "    gen_out = load_numpy(out_path+\"/Generated\"+str(layer)+\".npy\")\n",
    "    create_wav_file(gen_out,str(layer)+\".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_wav_file(image, \"test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(r\"C:\\Users\\ldscho\\spectro\\ml_expore\\test.wav\", duration=23)\n",
    "S = np.abs(librosa.stft(y))\n",
    "\n",
    "S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "plt.figure()\n",
    "librosa.display.specshow(S_db)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectrogram_and_back():\n",
    "    x, sr = librosa.load(r\"C:\\Users\\ldscho\\Downloads\\2.wav\", duration=11.87)\n",
    "\n",
    "    S = librosa.feature.melspectrogram(n_mels=512, y=x, sr=sr, S=None, n_fft=2048, hop_length=512, win_length=None, window='hann', center=True, pad_mode='constant', power=2.0, fmin=75, fmax=4000)\n",
    "    x_inv = librosa.feature.inverse.mel_to_audio(M=S, sr=22050, n_fft=2048, hop_length=512, n_iter=32, win_length=None, window='hann', center=True, pad_mode='constant', power=2.0, fmin=75, fmax=4000)\n",
    "\n",
    "    S = S.astype(np.uint8)\n",
    "    im = Image.fromarray(S)\n",
    "    im.save(\"S.png\")\n",
    "\n",
    "    sf.write(\"first.wav\", x_inv, sr)\n",
    "\n",
    "    return x_inv, S\n",
    "\n",
    "a= audio_to_spectrogram_and_back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_generate(path):\n",
    "    #[^\\]*(?=[.][a-zA-Z]+$)\n",
    "    pattern = re.compile(r'(.+)(\\\\)(?P<name>.+)(.wav)')\n",
    "    for music_name in os.listdir(path):\n",
    "        file_name = os.path.join(path, music_name)\n",
    "        if os.path.isfile(file_name):\n",
    "            match = list((re.finditer(pattern, file_name)))\n",
    "            name = match[0].groupdict()['name']\n",
    "            print(file_name)\n",
    "\n",
    "            #a = random.uniform(0,12)\n",
    "            #b = random.uniform(0,12)\n",
    "            #c = random.uniform(0,12)\n",
    "            #d = random.uniform(0,12)\n",
    "\n",
    "            a = 0\n",
    "            b = 3\n",
    "            c = 6\n",
    "            d = 9\n",
    "\n",
    "            w, sr = librosa.load(file_name, duration=11.87, offset=a)\n",
    "            x, sr = librosa.load(file_name, duration=11.87, offset=b)\n",
    "            y, sr = librosa.load(file_name, duration=11.87, offset=c)\n",
    "            z, sr = librosa.load(file_name, duration=11.87, offset=d)\n",
    "\n",
    "            W = librosa.feature.melspectrogram(n_mels=512, y=w, sr=sr, S=None, n_fft=2048, hop_length=512, win_length=None, window='hann', center=True, pad_mode='constant', power=2.0, fmin=75, fmax=4000)\n",
    "            X = librosa.feature.melspectrogram(n_mels=512, y=x, sr=sr, S=None, n_fft=2048, hop_length=512, win_length=None, window='hann', center=True, pad_mode='constant', power=2.0, fmin=75, fmax=4000)\n",
    "            Y = librosa.feature.melspectrogram(n_mels=512, y=y, sr=sr, S=None, n_fft=2048, hop_length=512, win_length=None, window='hann', center=True, pad_mode='constant', power=2.0, fmin=75, fmax=4000)\n",
    "            Z = librosa.feature.melspectrogram(n_mels=512, y=z, sr=sr, S=None, n_fft=2048, hop_length=512, win_length=None, window='hann', center=True, pad_mode='constant', power=2.0, fmin=75, fmax=4000)\n",
    "\n",
    "            lM_W = W.astype(np.uint8)\n",
    "            im_W = Image.fromarray(lM_W)\n",
    "            lM_X = X.astype(np.uint8)\n",
    "            im_X = Image.fromarray(lM_X)\n",
    "            lM_Y = Y.astype(np.uint8)\n",
    "            im_Y = Image.fromarray(lM_Y)\n",
    "            lM_Z = Z.astype(np.uint8)\n",
    "            im_Z = Image.fromarray(lM_Z)\n",
    "\n",
    "\n",
    "            im_W.save(\"a_\" + name + \".png\")\n",
    "            im_X.save(\"b_\" + name + \".png\")\n",
    "            im_Y.save(\"c_\" + name + \".png\")\n",
    "            im_Z.save(\"d_\" + name + \".png\")\n",
    "\n",
    "\n",
    "mel_generate(r\"C:\\Users\\ldscho\\spectro\\ml_expore\\converted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Too far lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   .....                                                                                           \n",
    "# ^PYJJJYYJ?!^.                                                                                     \n",
    "# P5     .:~!?YYJ?^.                                                                                \n",
    "# 5G           .:!JY57.                 :!^                                                         \n",
    "# :#!               ^YB!             ~J55JGP.                                                       \n",
    "#  7#.                ^G5:          :&?.   5B                                                       \n",
    "#   BJ                  ?5Y!.       J#     .PP^                                                     \n",
    "#   JB                    ^JG7      PY       !G5.                                                   \n",
    "#    PP                     :YG^    5P~J:  .J! B5                                                   \n",
    "#    .PP                      ~PY.  ^@P!.   :: ~@^                                                  \n",
    "#     .BJ            :~:        ?B!  J#^        BY             .::^~~:                              \n",
    "#       .BJ           ^YG5!.      ^BJ  J#:       ?B        .!Y5YYYJJ7?GY:                            \n",
    "#       :PY~.          .~JPGY!^:. .JG^^@~       7#     ~?5PY!.       .5#^                           \n",
    "#        ~JP?^         :?GY!?JY55J?PBGJ        GP ..?PP7:             J&.                          \n",
    "#           .!55^      ~&?:      .::...        .P5JJY5^            :^!!Y#:                          \n",
    "#              ~GY.    !&                                   .^!JJJY5?7!!.                           \n",
    "#                ?G7  .B5                                 ~YGJ7~:..                                 \n",
    "#                 .5G.:@:                               ^PP!.                                       \n",
    "#                   PP:&^                             .:BJ                                          \n",
    "#                   .PGB5                             !G@7.                                         \n",
    "#                     ?B@GY?J7!!!!!~                   J#JG?.                                       \n",
    "#                      .?BY^^!!!!!!G5.                 GY :JP5~                                     \n",
    "#                        :YG?      .?#~                PY    ~G5^                                   \n",
    "#                          :YG~      #7                PY      !G?.                                 \n",
    "#                            ~P5^   ^&:                PY       .?5Y~                               \n",
    "#                              ?#7  ?B                 PY          ~PJ:                             \n",
    "#                               ^YP7BJ                 PY     .^~77!7P&G7^                          \n",
    "#                   .~~!?7?!~:.   .P@P:                GY .~?P5J?7~~~~75GBGJ^                       \n",
    "#                 :55J7!~^!7JYY5?~ ^@7.                J&5PY~:            ?@#Y.                     \n",
    "#                 GP           :7Y5YG:                 .?!.                #7?G7                    \n",
    "#                 #7                                                      7#^ :5P~                  \n",
    "#                 #7                                                     J#^    ~P5!                \n",
    "#                 5B:                                             .::^~?P5:      ~?YPJ:             \n",
    "#                 .Y5YYY?7!^^^:........:^^^^.         ..:!????JJJYY5JJ?!^        ~5P7?P7            \n",
    "#                     .^^!7??JYJJJJJJJJYJ??JB~       ?BJYJ!^^^^...                 ~PY.             \n",
    "#                                           BJ       !&                              JB^            \n",
    "#                                           G5       ?@7.                             ?#.           \n",
    "#                                           ~&^      :&P5Y^                           .&^           \n",
    "#                                            &~       PP !GY.                         :&^           \n",
    "#                                           .&!       ~&.  YG!                        .&^           \n",
    "#                                            PP       .&?   ^5P7.                     JB.           \n",
    "#                                            ~&^       ?#     ^?PJ7:                .JB^            \n",
    "#                                             BJ       !&.      .^?YYJ~^.         :?PJ.             \n",
    "#                                             JB       Y#           .~?JYYJ?7~~~?557:               \n",
    "#                                             7#       !&.               .:~!777!:                  \n",
    "#                                             7#       7&                                           \n",
    "#                                             ^@~     .#J                                           \n",
    "#                                              GP     5G                                            \n",
    "#                                              :BY.  ?&:                                            \n",
    "#                                               .5GYPP^                                             \n",
    "#                                                 :7^   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9543722fc7f00247359e220ca540944f9128b8f6e10610f2bcbacc20ad2a6df1"
  },
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:real-fast3]",
   "language": "python",
   "name": "conda-env-real-fast3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
